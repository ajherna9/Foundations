}
# get some data
dfMPG <- mpg
dfMPG = select(dfMPG, manufacturer, hwy, displ)
ModMatrix = model.matrix(hwy ~ manufacturer + displ + I(displ^2), data = dfMPG)
vY  = dfMPG$hwy
mBeta = as.numeric(solve(t(ModMatrix) %*% ModMatrix) %*% (t(ModMatrix) %*% vY))
rmse(t(as.numeric(mBeta)%*%t(ModMatrix)) - dfMPG$hwy)
n = ncol(ModMatrix)
d = diag(1,n,n)
d[1,1] = 0
vBetaReg1 = as.numeric(solve(t(ModMatrix) %*% ModMatrix + (10 * d)) %*% (t(ModMatrix) %*% vY))
rmse(t(as.numeric(vBetaReg1)%*%t(ModMatrix)) - dfMPG$hwy)
dfMPG2 = mpg %>% mutate(hwy = 35 + (-3*displ) + rnorm(nrow(mpg), 0, 3))
ModMatrix2 = model.matrix(hwy ~ manufacturer + displ + I(displ^2), data = dfMPG2)
# poly model error
rmse(t(as.numeric(mBeta)%*%t(ModMatrix2)) - dfMPG2$hwy)
# regularized model error
rmse(t(as.numeric(vBetaReg1)%*%t(ModMatrix2)) - dfMPG2$hwy)
library(tidyverse)
library(splines)
library(mgcv)
library(rms)
setwd("C:/Users/ellen/OneDrive/Documents/Spring 2020/DA2/Section 1/Regression/Data")
Auto <- read.csv(file="Automobile Price Prediction.csv")
p <- ggplot(Auto, aes(x=horsepower, y=price))+geom_point()
p
modelBS <- lm(data = Auto, price ~  bs(horsepower, 3))
Auto$BSPrice <- predict(modelBS, data = Auto)
p <- ggplot(data=Auto) + geom_point(aes(x=horsepower, y = price), color = 'black')
p <- p + geom_smooth(aes(x=horsepower, y = price), se=FALSE, color = "blue")
p
Intercept <- modelBS$coefficients[1]
mb1 <- modelBS$coefficients[2]
mb2 <- modelBS$coefficients[3]
mb3 <- modelBS$coefficients[4]
rng <- range(Auto$horsepower)
div <- ((rng[2]-rng[1])/3)
a1 <- seq(rng[1], rng[1]+div, length.out = 10)
b1 <- seq(Intercept, Intercept+mb1, length.out = 10)
a2 <- seq(rng[1]+div, rng[1]+div+div, length.out = 10)
b2 <- seq(Intercept+mb1, Intercept+mb2, length.out = 10)
a3 <- seq(rng[1]+div+div, rng[2], length.out = 10)
b3 <- seq(Intercept+mb2, Intercept+mb3, length.out = 10)
tst <- data.frame(a1, b1, a2, b2, a3, b3)
p <- p + geom_line(data = tst, aes(x=a1, y = b1), color  = "red")
p <- p + geom_line(data = tst, aes(x=a2, y = b2), color  = "red")
p <- p + geom_line(data = tst, aes(x=a3, y = b3), color  = "red")
p
modelGAM <- gam(price ~ s(horsepower), data = Auto, family = gaussian(link = identity))
Auto$GAMPrice <- predict(modelGAM, data = Auto)
p <- p + geom_smooth(data = Auto, aes(x=horsepower, y = GAMPrice), se=FALSE, color = "red")
p
summary(modelGAM)
summary(modelBS)
library(ggplot2)
library(splines)
mydata <- read.csv(file="C:/Users/ellen/Documents/UH/Fall 2020/Data/Ex1LS.csv", header=TRUE, sep=",")
mydata$X1 <- mydata$X
p <- ggplot(data = mydata) + geom_point(aes(x = X1, y = Y))
p
model <- lm( formula = Y ~ X, mydata)
modelQ <- lm( formula = Y ~ X + I(X^2), mydata)
modelNS <- lm(data = mydata, Y ~ ns(X, 2)) # you can also specifically set knots, but beware
predData <- data.frame(X = seq(1, 4, .11)) # i'm doing this so we can see how the trained models perform
predData$Y <- predict(model, predData)
predData$Q <- predict(modelQ, predData)
predData$NS <- predict(modelNS, predData)
p <- p + geom_smooth(data=predData, aes(x=X, y = Y), se=FALSE, color = "black")
p <- p + geom_smooth(data=predData, aes(x=X, y = Q), se=FALSE, color = "red")
p <- p + geom_smooth(data=predData, aes(x=X, y = NS), se=FALSE, color = "blue")
p
summary(model)
summary(modelQ)
summary(modelNS)
library(ggplot2)
library(splines)
mydata <- read.csv(file="C:/Users/ellen/Documents/UH/Fall 2020/Data/Ex1LS.csv", header=TRUE, sep=",")
mydata$X1 <- mydata$X
p <- ggplot(data = mydata) + geom_point(aes(x = X1, y = Y))
p
model <- lm( formula = Y ~ X, mydata)
modelQ <- lm( formula = Y ~ X + I(X^2), mydata)
modelNS <- lm(data = mydata, Y ~ ns(X, 2)) # you can also specifically set knots, but beware
predData <- data.frame(X = seq(1, 4, .11)) # i'm doing this so we can see how the trained models perform
predData
predData$Y <- predict(model, predData)
predData$Q <- predict(modelQ, predData)
predData$NS <- predict(modelNS, predData)
p <- p + geom_smooth(data=predData, aes(x=X, y = Y), se=FALSE, color = "black")
p
p <- p + geom_smooth(data=predData, aes(x=X, y = Q), se=FALSE, color = "red")
p
p <- p + geom_smooth(data=predData, aes(x=X, y = NS), se=FALSE, color = "blue")
p
summary(model)
summary(modelQ)
summary(modelNS)
library(ggplot2)
library(splines)
setwd("C:/Users/ellen/Documents/Fall 2018/DA2/Section1/Regression/Data")
mydata <- read.csv(file="Ex1LS.csv", header=TRUE, sep=",")
mydata$X1 <- mydata$X
p <- ggplot(data = mydata) + geom_point(aes(x = X1, y = Y))
p
model <- lm( formula = Y ~ X, mydata)
modelQ <- lm( formula = Y ~ X + I(X^2), mydata)
modelNS <- lm(data = mydata, Y ~ ns(X, 2)) # you can also specifically set knots, but beware
predData <- data.frame(X = seq(1, 10, 1)) # i'm doing this so we can see how the trained models perform
# on a denser dataset
predData$Y <- predict(model, predData)
predData$Q <- predict(modelQ, predData)
predData$NS <- predict(modelNS, predData)
p <- ggplot(predData, aes(x=X, y=Y)) + geom_point()
p <- p + geom_point(data = predData, aes(x=X, y = Y), color = 'black')
p <- p + geom_point(data = predData, aes(x=X, y = Q), color = 'red')
p <- p + geom_point(data = predData, aes(x=X, y = NS), color = 'blue')
p <- p + geom_smooth(data=predData, aes(x=X, y = Y), se=FALSE, color = "black")
p <- p + geom_smooth(data=predData, aes(x=X, y = Q), se=FALSE, color = "red")
p <- p + geom_smooth(data=predData, aes(x=X, y = NS), se=FALSE, color = "blue")
p
library(ggplot2)
library(splines)
mydata <- read.csv(file="C:/Users/ellen/Documents/UH/Fall 2020/Data/Ex1LS.csv", header=TRUE, sep=",")
mydata$X1 <- mydata$X
p <- ggplot(data = mydata) + geom_point(aes(x = X1, y = Y))
p
model <- lm( formula = Y ~ X, mydata)
modelQ <- lm( formula = Y ~ X + I(X^2), mydata)
modelNS <- lm(data = mydata, Y ~ ns(X, 2)) # you can also specifically set knots, but beware
predData <- data.frame(X = seq(1, 4, .11)) # i'm doing this so we can see how the trained models perform
# on a denser dataset
predData$Y <- predict(model, predData)
predData$Q <- predict(modelQ, predData)
predData$NS <- predict(modelNS, predData)
p <- ggplot(predData, aes(x=X, y=Y)) + geom_point()
p <- p + geom_point(data = predData, aes(x=X, y = Y), color = 'black')
p <- p + geom_point(data = predData, aes(x=X, y = Q), color = 'red')
p <- p + geom_point(data = predData, aes(x=X, y = NS), color = 'blue')
p <- p + geom_smooth(data=predData, aes(x=X, y = Y), se=FALSE, color = "black")
p <- p + geom_smooth(data=predData, aes(x=X, y = Q), se=FALSE, color = "red")
p <- p + geom_smooth(data=predData, aes(x=X, y = NS), se=FALSE, color = "blue")
p
library(ggplot2)
library(splines)
setwd("C:/Users/ellen/Documents/Fall 2018/DA2/Section1/Regression/Data")
mydata <- read.csv(file="Ex1LS.csv", header=TRUE, sep=",")
mydata$X1 <- mydata$X
p <- ggplot(data = mydata) + geom_point(aes(x = X1, y = Y))
p
model <- lm( formula = Y ~ X, mydata)
modelQ <- lm( formula = Y ~ X + I(X^2), mydata)
modelNS <- lm(data = mydata, Y ~ ns(X, 2)) # you can also specifically set knots, but beware
library(ggplot2)
library(splines)
mydata <- read.csv(file="C:/Users/ellen/Documents/UH/Fall 2020/Data/Ex1LS.csv", header=TRUE, sep=",")
mydata$X1 <- mydata$X
p <- ggplot(data = mydata) + geom_point(aes(x = X1, y = Y))
p
model <- lm( formula = Y ~ X, mydata)
modelQ <- lm( formula = Y ~ X + I(X^2), mydata)
modelNS <- lm(data = mydata, Y ~ ns(X, 2)) # you can also specifically set knots, but beware
predData <- data.frame(X = seq(1, 4, .11)) # i'm doing this so we can see how the trained models perform
predData$Y <- predict(model, predData)
predData$Q <- predict(modelQ, predData)
predData$NS <- predict(modelNS, predData)
p <- ggplot(predData, aes(x=X, y=Y)) + geom_point()
p <- p + geom_point(data = predData, aes(x=X, y = Y), color = 'black')
p <- p + geom_point(data = predData, aes(x=X, y = Q), color = 'red')
p <- p + geom_point(data = predData, aes(x=X, y = NS), color = 'blue')
p <- p + geom_smooth(data=predData, aes(x=X, y = Y), se=FALSE, color = "black")
p <- p + geom_smooth(data=predData, aes(x=X, y = Q), se=FALSE, color = "red")
p <- p + geom_smooth(data=predData, aes(x=X, y = NS), se=FALSE, color = "blue")
p
library(ggplot2)
library(splines)
mydata <- read.csv(file="C:/Users/ellen/Documents/UH/Fall 2020/Data/Ex1LS.csv", header=TRUE, sep=",")
mydata$X1 <- mydata$X
p <- ggplot(data = mydata) + geom_point(aes(x = X1, y = Y))
p
model <- lm( formula = Y ~ X, mydata)
modelQ <- lm( formula = Y ~ X + I(X^2), mydata)
modelNS <- lm(data = mydata, Y ~ ns(X, 4)) # you can also specifically set knots, but beware
predData <- data.frame(X = seq(1, 4, .11)) # i'm doing this so we can see how the trained models perform
# on a denser dataset
predData$Y <- predict(model, predData)
predData$Q <- predict(modelQ, predData)
predData$NS <- predict(modelNS, predData)
p <- ggplot(predData, aes(x=X, y=Y)) + geom_point()
p <- p + geom_point(data = predData, aes(x=X, y = Y), color = 'black')
p <- p + geom_point(data = predData, aes(x=X, y = Q), color = 'red')
p <- p + geom_point(data = predData, aes(x=X, y = NS), color = 'blue')
p <- p + geom_smooth(data=predData, aes(x=X, y = Y), se=FALSE, color = "black")
p <- p + geom_smooth(data=predData, aes(x=X, y = Q), se=FALSE, color = "red")
p <- p + geom_smooth(data=predData, aes(x=X, y = NS), se=FALSE, color = "blue")
p
library(ggplot2)
library(splines)
mydata <- read.csv(file="C:/Users/ellen/Documents/UH/Fall 2020/Data/Ex1LS.csv", header=TRUE, sep=",")
mydata$X1 <- mydata$X
p <- ggplot(data = mydata) + geom_point(aes(x = X1, y = Y))
p
model <- lm( formula = Y ~ X, mydata)
modelQ <- lm( formula = Y ~ X + I(X^2), mydata)
modelNS <- lm(data = mydata, Y ~ ns(X, 2)) # you can also specifically set knots, but beware
predData <- data.frame(X = seq(1, 4, .11)) # i'm doing this so we can see how the trained models perform
# on a denser dataset
predData$Y <- predict(model, predData)
predData$Q <- predict(modelQ, predData)
predData$NS <- predict(modelNS, predData)
p <- ggplot(predData, aes(x=X, y=Y)) + geom_point()
p <- p + geom_point(data = predData, aes(x=X, y = Y), color = 'black')
p <- p + geom_point(data = predData, aes(x=X, y = Q), color = 'red')
p <- p + geom_point(data = predData, aes(x=X, y = NS), color = 'blue')
p <- p + geom_smooth(data=predData, aes(x=X, y = Y), se=FALSE, color = "black")
p <- p + geom_smooth(data=predData, aes(x=X, y = Q), se=FALSE, color = "red")
p <- p + geom_smooth(data=predData, aes(x=X, y = NS), se=FALSE, color = "blue")
p
summary(model)
summary(modelQ)
summary(modelNS)
Auto <- read.csv(file="C:/Users/ellen/Documents/UH/Fall 2020/Github Staging/EllenwTerry/Archive/Data_Files/Automobile Price Prediction.csv")
p <- ggplot(Auto, aes(x=horsepower, y=price))+geom_point()
p
model <- lm(price ~ horsepower + highway.mpg, data = Auto)
modelQ <- lm( formula = price ~ horsepower + I(horsepower^2) + highway.mpg + I(highway.mpg^2), Auto)
modelNS <- lm(data = Auto, price ~  ns(horsepower, 5) + ns(highway.mpg, 5))
predData <- data.frame(horsepower = seq(min(Auto$horsepower), max(Auto$horsepower), length.out = 50), highway.mpg = seq(min(Auto$highway.mpg), max(Auto$highway.mpg), length.out = 50))
predData$Y <- predict(model, predData)
predData$Q <- predict(modelQ, predData)
predData$NS <- predict(modelNS, predData)
p <- ggplot(predData, aes(x=X, y=Y))
p <- p + geom_point(data = predData, aes(x=horsepower, y = Y), color = 'black')
p <- p + geom_point(data = predData, aes(x=horsepower, y = Q), color = 'red')
p <- p + geom_point(data = predData, aes(x=horsepower, y = NS), color = 'blue')
p <- p + geom_smooth(data=predData, aes(x=horsepower, y = Y), se=FALSE, color = "black")
p <- p + geom_smooth(data=predData, aes(x=horsepower, y = Q), se=FALSE, color = "red")
p <- p + geom_smooth(data=predData, aes(x=horsepower, y = NS), se=FALSE, color = "blue")
p
p <- p + geom_point(data = Auto, aes(x=horsepower, y=price))
p
library(ggplot2)
library(splines)
mydata <- read.csv(file="C:/Users/ellen/Documents/UH/Fall 2020/Data/Ex1LS.csv", header=TRUE, sep=",")
mydata$X1 <- mydata$X
p <- ggplot(data = mydata) + geom_point(aes(x = X1, y = Y))
p
model <- lm( formula = Y ~ X, mydata)
modelQ <- lm( formula = Y ~ X + I(X^2), mydata)
modelNS <- lm(data = mydata, Y ~ ns(X, 2)) # you can also specifically set knots, but beware
predData <- data.frame(X = seq(1, 4, .11)) # i'm doing this so we can see how the trained models perform
# on a denser dataset
predData$Y <- predict(model, predData)
predData$Q <- predict(modelQ, predData)
predData$NS <- predict(modelNS, predData)
p <- ggplot(predData, aes(x=X, y=Y)) + geom_point()
p <- p + geom_point(data = predData, aes(x=X, y = Y), color = 'black')
p <- p + geom_point(data = predData, aes(x=X, y = Q), color = 'red')
p <- p + geom_point(data = predData, aes(x=X, y = NS), color = 'blue')
p <- p + geom_smooth(data=predData, aes(x=X, y = Y), se=FALSE, color = "black")
p <- p + geom_smooth(data=predData, aes(x=X, y = Q), se=FALSE, color = "red")
p <- p + geom_smooth(data=predData, aes(x=X, y = NS), se=FALSE, color = "blue")
p
summary(model)
summary(modelQ)
summary(modelNS)
modelNS2 <- lm(data = mydata, Y ~ ns(X, 4)) # you can also specifically set knots, but beware
predData$NS2 <- predict(modelNS2, predData)
p <- p + geom_smooth(data=predData, aes(x=X, y = NS2), se=FALSE, color = "green")
p
library(ggplot2)
library(splines)
mydata <- read.csv(file="C:/Users/ellen/Documents/UH/Fall 2020/Data/Ex1LS.csv", header=TRUE, sep=",")
mydata$X1 <- mydata$X
p <- ggplot(data = mydata) + geom_point(aes(x = X1, y = Y))
p
p <- ggplot(data = mydata) + geom_point(aes(x = X1, y = Y, size = 3))
p
p <- ggplot(data = mydata) + geom_point(aes(x = X1, y = Y, size = 2))
p
p <- ggplot(data = mydata) + geom_point(aes(x = X1, y = Y), size = 2)
p
p <- p + geom_point(data = predData, aes(x=X, y = Y), color = 'black')
p
library(ggplot2)
library(splines)
mydata <- read.csv(file="C:/Users/ellen/Documents/UH/Fall 2020/Data/Ex1LS.csv", header=TRUE, sep=",")
mydata$X1 <- mydata$X
p <- ggplot(data = mydata) + geom_point(aes(x = X1, y = Y), size = 2)
p
model <- lm( formula = Y ~ X, mydata)
modelQ <- lm( formula = Y ~ X + I(X^2), mydata)
modelNS <- lm(data = mydata, Y ~ ns(X, 2)) # you can also specifically set knots, but beware
predData <- data.frame(X = seq(1, 4, .11)) # i'm doing this so we can see how the trained models perform
predData$Y <- predict(model, predData)
predData$Q <- predict(modelQ, predData)
predData$NS <- predict(modelNS, predData)
p <- p + geom_point(data = predData, aes(x=X, y = Y), color = 'black')
p
library(ggplot2)
library(splines)
mydata <- read.csv(file="C:/Users/ellen/Documents/UH/Fall 2020/Data/Ex1LS.csv", header=TRUE, sep=",")
mydata$X1 <- mydata$X
p <- ggplot(data = mydata) + geom_point(aes(x = X1, y = Y), size = 2)
p
model <- lm( formula = Y ~ X, mydata)
modelQ <- lm( formula = Y ~ X + I(X^2), mydata)
modelNS <- lm(data = mydata, Y ~ ns(X, 2)) # you can also specifically set knots, but beware
predData <- data.frame(X = seq(1, 4, .11)) # i'm doing this so we can see how the trained models perform
# on a denser dataset
predData$Y <- predict(model, predData)
predData$Q <- predict(modelQ, predData)
predData$NS <- predict(modelNS, predData)
p <- p + geom_point(data = predData, aes(x=X, y = Y), color = 'black')
p <- p + geom_point(data = predData, aes(x=X, y = Q), color = 'red')
p <- p + geom_point(data = predData, aes(x=X, y = NS), color = 'blue')
p <- p + geom_smooth(data=predData, aes(x=X, y = Y), se=FALSE, color = "black")
p <- p + geom_smooth(data=predData, aes(x=X, y = Q), se=FALSE, color = "red")
p <- p + geom_smooth(data=predData, aes(x=X, y = NS), se=FALSE, color = "blue")
p
summary(model)
summary(modelQ)
summary(modelNS)
modelNS2 <- lm(data = mydata, Y ~ ns(X, 4)) # you can also specifically set knots, but beware
predData$NS2 <- predict(modelNS2, predData)
p <- p + geom_smooth(data=predData, aes(x=X, y = NS2), se=FALSE, color = "green")
p
library(ggplot2)
library(splines)
mydata <- read.csv(file="C:/Users/ellen/Documents/UH/Fall 2020/Data/Ex1LS.csv", header=TRUE, sep=",")
mydata$X1 <- mydata$X
p <- ggplot(data = mydata) + geom_point(aes(x = X1, y = Y), size = 3)
p
p <- ggplot(data = mydata) + geom_point(aes(x = X1, y = Y), size = 4)
p
model <- lm( formula = Y ~ X, mydata)
modelQ <- lm( formula = Y ~ X + I(X^2), mydata)
modelNS <- lm(data = mydata, Y ~ ns(X, 2)) # you can also specifically set knots, but beware
predData <- data.frame(X = seq(1, 4, .11)) # i'm doing this so we can see how the trained models perform
# on a denser dataset
predData$Y <- predict(model, predData)
predData$Q <- predict(modelQ, predData)
predData$NS <- predict(modelNS, predData)
p <- p + geom_point(data = predData, aes(x=X, y = Y), color = 'black')
p <- p + geom_point(data = predData, aes(x=X, y = Q), color = 'red')
p <- p + geom_point(data = predData, aes(x=X, y = NS), color = 'blue')
p <- p + geom_smooth(data=predData, aes(x=X, y = Y), se=FALSE, color = "black")
p <- p + geom_smooth(data=predData, aes(x=X, y = Q), se=FALSE, color = "red")
p <- p + geom_smooth(data=predData, aes(x=X, y = NS), se=FALSE, color = "blue")
p
summary(model)
summary(modelQ)
summary(modelNS)
modelNS2 <- lm(data = mydata, Y ~ ns(X, 5)) # you can also specifically set knots, but beware
predData$NS2 <- predict(modelNS2, predData)
p <- p + geom_smooth(data=predData, aes(x=X, y = NS2), se=FALSE, color = "green")
p
library(ggplot2)
library(splines)
mydata <- read.csv(file="C:/Users/ellen/Documents/UH/Fall 2020/Data/Ex1LS.csv", header=TRUE, sep=",")
mydata$X1 <- mydata$X
p <- ggplot(data = mydata) + geom_point(aes(x = X1, y = Y), size = 4)
p
model <- lm( formula = Y ~ X, mydata)
modelQ <- lm( formula = Y ~ X + I(X^2), mydata)
modelNS <- lm(data = mydata, Y ~ ns(X, 2)) # you can also specifically set knots, but beware
predData <- data.frame(X = seq(1, 4, .11)) # i'm doing this so we can see how the trained models perform
# on a denser dataset
predData$Y <- predict(model, predData)
predData$Q <- predict(modelQ, predData)
predData$NS <- predict(modelNS, predData)
p <- p + geom_point(data = predData, aes(x=X, y = Y), color = 'black')
p <- p + geom_point(data = predData, aes(x=X, y = Q), color = 'red')
p <- p + geom_point(data = predData, aes(x=X, y = NS), color = 'blue')
p <- p + geom_smooth(data=predData, aes(x=X, y = Y), se=FALSE, color = "black")
p <- p + geom_smooth(data=predData, aes(x=X, y = Q), se=FALSE, color = "red")
p <- p + geom_smooth(data=predData, aes(x=X, y = NS), se=FALSE, color = "blue")
p
summary(model)
summary(modelQ)
summary(modelNS)
modelNS2 <- lm(data = mydata, Y ~ ns(X, 4)) # you can also specifically set knots, but beware
predData$NS2 <- predict(modelNS2, predData)
p <- p + geom_smooth(data=predData, aes(x=X, y = NS2), se=FALSE, color = "green")
p
summary(modelNS2)
Auto <- read.csv(file="C:/Users/ellen/Documents/UH/Fall 2020/Github Staging/EllenwTerry/Archive/Data_Files/Automobile Price Prediction.csv")
p <- ggplot(Auto, aes(x=horsepower, y=price))+geom_point()
p
model <- lm(price ~ horsepower + highway.mpg, data = Auto)
modelQ <- lm( formula = price ~ horsepower + I(horsepower^2) + highway.mpg + I(highway.mpg^2), Auto)
modelNS <- lm(data = Auto, price ~  ns(horsepower, 5) + ns(highway.mpg, 5))
predData <- data.frame(horsepower = seq(min(Auto$horsepower), max(Auto$horsepower), length.out = 50), highway.mpg = seq(min(Auto$highway.mpg), max(Auto$highway.mpg), length.out = 50))
predData$Y <- predict(model, predData)
predData$Q <- predict(modelQ, predData)
predData$NS <- predict(modelNS, predData)
p <- ggplot(predData, aes(x=X, y=Y))
p <- p + geom_point(data = predData, aes(x=horsepower, y = Y), color = 'black')
p <- p + geom_point(data = predData, aes(x=horsepower, y = Q), color = 'red')
p <- p + geom_point(data = predData, aes(x=horsepower, y = NS), color = 'blue')
p <- p + geom_smooth(data=predData, aes(x=horsepower, y = Y), se=FALSE, color = "black")
p <- p + geom_smooth(data=predData, aes(x=horsepower, y = Q), se=FALSE, color = "red")
p <- p + geom_smooth(data=predData, aes(x=horsepower, y = NS), se=FALSE, color = "blue")
p
p <- p + geom_point(data = Auto, aes(x=horsepower, y=price))
p
summary(model)
summary(modelQ)
summary(modelNS)
library(tidyverse)
library(splines)
library(mgcv)
library(rms)
setwd("C:/Users/ellen/OneDrive/Documents/Spring 2020/DA2/Section 1/Regression/Data")
Auto <- read.csv(file="Automobile Price Prediction.csv")
p <- ggplot(Auto, aes(x=horsepower, y=price))+geom_point()
p
modelBS <- lm(data = Auto, price ~  bs(horsepower, 3))
Auto$BSPrice <- predict(modelBS, data = Auto)
p <- ggplot(data=Auto) + geom_point(aes(x=horsepower, y = price), color = 'black')
p <- p + geom_smooth(aes(x=horsepower, y = price), se=FALSE, color = "blue")
p
Intercept <- modelBS$coefficients[1]
mb1 <- modelBS$coefficients[2]
mb2 <- modelBS$coefficients[3]
mb3 <- modelBS$coefficients[4]
rng <- range(Auto$horsepower)
div <- ((rng[2]-rng[1])/3)
## coefficients of the first model
a1 <- seq(rng[1], rng[1]+div, length.out = 10)
b1 <- seq(Intercept, Intercept+mb1, length.out = 10)
a2 <- seq(rng[1]+div, rng[1]+div+div, length.out = 10)
b2 <- seq(Intercept+mb1, Intercept+mb2, length.out = 10)
a3 <- seq(rng[1]+div+div, rng[2], length.out = 10)
b3 <- seq(Intercept+mb2, Intercept+mb3, length.out = 10)
tst <- data.frame(a1, b1, a2, b2, a3, b3)
p <- p + geom_line(data = tst, aes(x=a1, y = b1), color  = "red")
p <- p + geom_line(data = tst, aes(x=a2, y = b2), color  = "red")
p <- p + geom_line(data = tst, aes(x=a3, y = b3), color  = "red")
p
modelGAM <- gam(price ~ s(horsepower), data = Auto, family = gaussian(link = identity))
Auto$GAMPrice <- predict(modelGAM, data = Auto)
p <- p + geom_smooth(data = Auto, aes(x=horsepower, y = GAMPrice), se=FALSE, color = "red")
p
summary(modelGAM)
summary(modelBS)
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(stringr)
library(lubridate)
library(kableExtra)
rmse <- function(error)
{
sqrt(mean(error^2))
}
# get some data
dfMPG <- mpg
# lets say we sample data at 2 different times
# and different manufacturers are available at different times
dfSample1 = filter(dfMPG, manufacturer %in% c("chevrolet", "dodge", "jeep"))
dfSample1 = select(dfSample1, manufacturer, hwy, displ)
dfSample2 = filter(dfMPG, manufacturer %in% c("volkswagen", "toyota", "audi") & fl != 'd' & (displ < 5 | hwy <35))
dfSample2 = select(dfSample2, manufacturer, hwy, displ)
ModMatrix = model.matrix(hwy ~  displ + I(displ^2), data = dfSample1)
vY  = dfSample1$hwy
# solve for Betas
mBeta = as.numeric(solve(t(ModMatrix) %*% ModMatrix) %*% (t(ModMatrix) %*% vY))
# error estimated from training data
dfSample1$yhat1 = t(as.numeric(mBeta)%*%t(ModMatrix))
rmse(dfSample1$yhat1 - dfSample1$hwy)
p = ggplot(data = dfSample1, aes(x = displ, y = hwy)) +
geom_point() +
geom_smooth(aes(y = yhat1)) +
theme(
panel.background = element_rect(fill = "white")
)
p
n = ncol(ModMatrix)
d = diag(1,n,n)
d[1,1] = 0 # set the intercept term
vBetaReg1 = as.numeric(solve(t(ModMatrix) %*% ModMatrix + (10 * d)) %*% (t(ModMatrix) %*% vY))
vBetaReg2 = as.numeric(solve(t(ModMatrix) %*% ModMatrix + (5 * d)) %*% (t(ModMatrix) %*% vY))
vBetaReg3 = as.numeric(solve(t(ModMatrix) %*% ModMatrix + (2 * d)) %*% (t(ModMatrix) %*% vY))
vBetaReg4 = as.numeric(solve(t(ModMatrix) %*% ModMatrix + (1 * d)) %*% (t(ModMatrix) %*% vY))
p = ggplot(data = dfSample1, aes(x = displ, y = hwy)) +
geom_point() +
geom_smooth(aes(y = t(as.numeric(mBeta)%*%t(ModMatrix))), color = "blue") +
geom_smooth(aes(y = t(as.numeric(vBetaReg1)%*%t(ModMatrix))), color = "green") +
geom_smooth(aes(y = t(as.numeric(vBetaReg2)%*%t(ModMatrix))), color = "red") +
geom_smooth(aes(y = t(as.numeric(vBetaReg3)%*%t(ModMatrix))), color = "yellow") +
geom_smooth(aes(y = t(as.numeric(vBetaReg4)%*%t(ModMatrix))), color = "purple") +
theme(
panel.background = element_rect(fill = "white")
)
p
ModMatrix2 = model.matrix(hwy ~  displ + I(displ^2), data = dfSample2)
p = ggplot(data = dfSample2, aes(x = displ, y = hwy)) +
geom_point() +
geom_smooth(aes(y = t(as.numeric(mBeta)%*%t(ModMatrix2))), color = "blue") +
geom_smooth(aes(y = t(as.numeric(vBetaReg1)%*%t(ModMatrix2))), color = "green") +
geom_smooth(aes(y = t(as.numeric(vBetaReg2)%*%t(ModMatrix2))), color = "red") +
geom_smooth(aes(y = t(as.numeric(vBetaReg3)%*%t(ModMatrix2))), color = "yellow") +
geom_smooth(aes(y = t(as.numeric(vBetaReg4)%*%t(ModMatrix2))), color = "purple") +
theme(
panel.background = element_rect(fill = "white") # I do this so it's easier to see in  class
)
p
rmse(t(as.numeric(mBeta)%*%t(ModMatrix2)) - dfSample2$hwy)
rmse(t(as.numeric(vBetaReg1)%*%t(ModMatrix2)) - dfSample2$hwy)
rmse(t(as.numeric(vBetaReg2)%*%t(ModMatrix2)) - dfSample2$hwy)
rmse(t(as.numeric(vBetaReg3)%*%t(ModMatrix2)) - dfSample2$hwy)
rmse(t(as.numeric(vBetaReg4)%*%t(ModMatrix2)) - dfSample2$hwy)
